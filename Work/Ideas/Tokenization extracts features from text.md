# Tokenization extracts features from text.
In order to proceed with [[NLP]], we need to make the text *machine readable.* This is done through an [[embedding]] protocol, and [[tokenization]] is such a protocol. 

---
#idea/compsci/data-science/NLP 