---
origin: 2022-06-05
aliases: [tokenize, tokenizes, tokenized]
---
# Tokenization
---
Tokenization is the process of breaking down a string of text into its component parts. It's a standard part of [[NLP]], and is very similar to [[embedding]].

---
```dataview
LIST 
FROM [[tokenization]]
AND "Ideas"
AND -outgoing([[tokenization]])
```

