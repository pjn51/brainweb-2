# Metis Notes for Tuesday, Feb 16th
`LINKS:` [[metis week 7]]
`TAGS:` #meeting/career

---
> [!info]
> Today is the second day of [[metis week 7]]. I missed this day entirely. These notes come from my review of the recorded lectures.

## Lecture - [[topic modeling]]
Topic modleing is the process of uncovering topics in documents. While [[clustering]] is a *hard partition,* topic modeling is not. This means that a document can fall under multiple topic categories. 

This process helps us determine the real topic of a text document, even when we can't map individual words to individual topic categories. 

First, we have to talk about what a *topic* really is. We can think of a topic *probabilistically,* as a probability distribution of individual words. For example, a document with the topic "NBA" would have a high probability of containing the word "ball," a medium probability of containing the word "play," and a low probability of containing the word "trombone." 

The general process here is to create a *term matrix* for each document, the same way that we would when using a count vectorizer. Then, we can multiply the frequency of each word in the document by the probability of word X appearing in topic A, B, or C. We can use the aggregate score from performing this process on every word in the document to predict the likelihood of the document being about topic A, B, or C. 

Mathematically, this is just a matrix multiplication problem. 

At the end of this process, we still have to name our topic manually, since this is an [[unsupervised learning]] method. 

This method has a lot in common with [[PCA]] and [[dimension reduction]] in general.