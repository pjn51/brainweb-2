# Metis Notes for Wednesday, Jan 13th
`LINKS:` [[metis week 2]]
#meeting/career

---
Today we will start off with pair programming, and then we have a lecture on hypothesis testing, followed by a lecture on the selenium package for web scraping, and then we have a guest speaker. 

# Pair programming exercise
We are doing multiplication of [[matrices]] to represent [[matrix inverse & systems of equations|systems of equations]].

$$
\begin{vmatrix}5&3&7\\2&4&1\end{vmatrix}
* w =
\begin{vmatrix}537\\241\end{vmatrix}
$$

This is basically a system of equations.

- When there are the same number of equations and variables, then we have just one possible solution.
- When E < V, we have an infinite number of solutions. 
- When E > V, we have no solutions. 
- These above rules are generally true, but there are exceptions. 
	- For instance, 
$$x+y=4$$
$$x+y=8$$
	- has no solution.
- This becomes more intuitive if we thing geometrically. 
- If we think of equations as lines, we can see these rules more clearly.
- When solving a linear system of equations, we're just trying to find the intersection of all the lines of each equation, in a dimensional space of n-dimensions, where n is the number of variables that exist. 
- In python,
	- We represent these systems using numpy
```python
import numpy as np

x = np.matrix([5,3,7],[2,4,1])
y = np.matrix([537],[241])

w = np.linalg.inx(x).dot(y)
```
- We use the matrix inverse because here's how we would solve this if it was a regular equation...
$$xw=y$$
$$w=\frac{y}{x}$$

- But we can't divide matrices, we have to use $y*x^{-1}$ instead. And we do that with matrices by using the matrix inverse of x. 
- We could also use the following shortcut...`np.linalg.solve(x,y)` which will spit out the answer matrix `w`.
- What does this have to do with a [[linear regression]]? 
	- We will end up in a situation where E > V, because every observation is like an equation, and every feature is like a variable. So unless we have more features than observations, that's our situation. 
	- The mission is to find the coefficients that precede each feature that will allow the equation to resolve for each observation. 
	- But this means we will have no solutions! What can we do??? We won't have a **perfect** solution, but we can find a point that gets close to working with lots of equations / observations. 
	- This is why all LinRegs have some error present. It would be literally impossible to have no error. We just seek to **minimize the error**. 

---
`LINKS:` [[metis week 2]]

# Lecture: advanced [[web scraping]]
- Some websites hate robots. We have to get around that if we want to scrape.
- Websites find robots based on the frequency of access. We can set limits so that only a certain number of requests are made per minute. 
- We just have to add a little timer
```python
import time

for page in page_list:
	<scrape the page>
	
	time.sleep(2)
```
- Using `time.sleep(2)`, we can tell python to wait a certain number of seconds before proceeding. 
	- But this might take forever.
- We could try and find the sweet spot by accessing a lot of pages, and then sleeping. We have to figure out how fast we can scrape before the website figures out that we're scraping. 
- Better yet, we could make the time slept a random number, imitating human behavior even better than just waiting a set time period.
- Some websites are just too damn smart. They can see that we're using automated tools. If this happens, we have to be even more clever. 
	- We have to use tools that make it seem like we're using a real browser to access the site. 
	- We create a user agent that mimics a browser, and so `requests` can use this info. 
	- We could even create a bunch of user agents so that the site might think we're a public IP or something like a library. That could let us scrape even faster. 

# Lecture: [[web scraping]] with selenium
- What if we want to scrape a dynamic site, like YouTube? What if we want to predict likes on a video based on the title? 
- We can't just scrape this site like normal. Even if we get the div we want, and pull the correct div, nothing will show up. This is because YouTube doesn't have pre-built pages for every video search query. That would be insane. 
	- Instead, JavaScript reaches out to the server to render the page whenever somebody asks for a specific search query. 
	- This means that it's a ==dynamically generated page==. 
- We need ==selenium== for this. 
- Importing selenium
	- We need a web driver called ChromeDriver
	- We need to pass `from selenium.webdriver.common.keys import Keys`

```python
query = "[[data science]]"
youtube_search = "https://www.youtube.com/results?search_query="
youtube_query = youtube_search + query.replace(' ', '+')

from selenium import webdriver
from selenium.webdriver.common.keys import Keys

chromedriver = "/Applications/chromedriver" # path to the chromedriver executable
os.environ["webdriver.chrome.driver"] = chromedriver

driver = webdriver.Chrome(chromedriver)
driver.get(youtube_query)
```

- Executing a selenium pull
	- First we create the query we want for youtube, and we get the url that we will need for the search. Then we create the chrome driver object that will control the browser.
	- This final line will launch Chrome, under machine control. It will execute the youtube query and pull the html from the page.
- Limitations
	- In the above example, only about 20 videos will show up. This is because only the first 20 results are on the first page. But if there's an infinite scroll, selenium can deal with that and can go all the way to the end. BeautifulSoup can't do that. 
- Interacting with pages
```python
for i in range(5):
    #Scroll
    driver.execute_script(
        "window.scrollTo(0, document.documentElement.scrollHeight);" #Alternatively, document.body.scrollHeight
    )
    
    #Wait for page to load
    time.sleep(1)
```
- The above code will deal with an infinite scroll, scrolling to the bottom of the page every second so that the results keep loading. 

- We can even open the youtube filter window to filter the results to find only short videos using selenium.
```python
filter_button = driver.find_element_by_xpath(
    '//a[contains(@class, "ytd-toggle-button")]'
)
filter_button.click()

short_link = driver.find_element_by_xpath(
    '//div[contains(@title, "Search for Short")]'
)
short_link.click()
```

# Lecture - [[data types]] and NaNs in linear regressions
- For [[natural amenity regression]] our target is numerical. 
- The features might be numerical or categorical. 
- Overview
	- Numeric
		- Continuous
		- Discrete
	- Categorical
		- Nominal
		- Ordinal
- Numeric [[data]]
	- Both continuous and discrete data are great for regressions. 
- Categorical
	- This is the tricky one. There are differences between nominal and ordinal data types.
	- We have to make the categorical fields numerical. 
	- For the nominal data...
		- We can use dummy variables / one hot encoding like we talked about yesterday. Remember to eliminate the redundancy by having one less column than there are categories. 
		- There can be combinations of categories. For instance, this still works for movie genres, even if some moves are in multiple genres. Still works. However you might not be able to drop one of the columns since there wouldn't be redundancy. 
	- For the ordinal data...
		- This data exists in a natural order. In housing, this could be a column talking about if houses have a partial garage, full garage, or none. We can turn this into a numerical range, where each entry is 0, 0.5, or 1. 
		- We do this to capture the "in-between-ness" of the half-garage in this example. 
		- We are making an assumption that there is only one coefficient that determines the relationship between the garage and the final price. If we keep the categories as their own columns, the model has more ==degrees of freedom==. 
			- For example, if you are assigning half garage to a value of 0.5, you are ==assuming== that the half garage is exactly half as valuable as a full garage.
			- Be careful of this if you don't have that much domain knowledge. 
- Dummy variables and NaN values
	- If we have NaNs, we have to either drop or compute them. 
	- If the target is missing, we have to drop it. 
	- If a feature has missing values, we can compute them or drop them. 
		- Dropping is simplest. The limitations are that we lose a lot of data. Also, sometimes NaNs are not evenly distributed across the dataset. 
			- What if you had a housing column that was 'last sold price' and every new house had NaN for that? If you dropped all those, now you've created an un-representative sample for your analysis. This is called ==selection bias==. 
		- If we don't want to drop, we have to compute new values for the NaNs.
			- This is also hard. We have to be very specific about imputing these data. If a housing dataset has some missing square footage values, we should select new values from the average from the *same ZIP and the same number of bedrooms* for example. 

# Lecture - [[probability]] review
- Opening example: If we have two digits, how many combinations of numbers are there?
	- For both digits, we have options from zero to nine. That means we have 100 possible values, from 00 to 99. 
	- If we have four digits, we have $10^4$ options.
	- This is called permutation with replacement. 
- What if we can't reuse any numbers?
	- For two digits, we have 10 options for the first digit, 9 for the second. This means we have 90 possibilities. 
	- For four digits, we have 10 options for the first digit, 9 for the second, 8 for the third, etc. 
	- Formally, we have options $n!-(n-r)!$ where r is the number of digits. 
	- This is called ==permutation==. 
- What if order doesn't matter? AKA 51 == 15
	- With three digits, the number of possibilities is $10*9*8/3!$ because there are $3!$ possible orderings for a three digit number. 
	- This is called ==combination==. 
- What is probability?
	- It's the number of favorable outcomes divided by the total number of possible outcomes for a situation. 
	- We use the above situations to calculate the total number of possible outcomes so that we can calculate probability. 
- Probability questions
	- If we toss a coin twice, what's the probability of 2 heads?
		- This would be 1/4. There are four possible outcomes, and we want one of them to happen. HH, TT, HT, TH, 
	- If we toss a coin three times, whats the prob of at least 2 heads?
		- Possibilities are HHH, HHT, HTH, THH, HTT, THH, THT
		- So prob is 4/7
- Combining probabilities
	- When it's a matter of either / or, we can add probabilities. 
	- When things have to both happen, we multiply. 
- Formalizing these equations
	- P(A and B) = P(A/B) $*$ P(B)
	- P(A or B) = P(A) + P(B) - P(A and B)
- Another question
	- If there is a group of 7 people with 2 dice, we want to pick a winner out of the 7 using 2 dice. How can we do that in the fewest possible rolls?
- ==Expected value==: probability times value. 
	- This is the number that we will converge towards as we conduct more and more coin flips, dice rolls, etc. 
	- For a coin, it's 0.5 (if head is 1, tail is 0)
	- For a die, its 3.5. For the sum of two dice, it's 7. 
- Let's talk about the lottery
	- If 1000 $1 tickets are sold, and the jackpot is $1,000, what would the probability of winning be if we played 1,000 times in a row?
	- P(win)=1/1000
	- P(lose) = 999/1000
	- P(lose twice) = 999/1000^2
	- P(never win) = 999/1000^1000
	- P(win at least once) = 1-(999/1000)^1000 = 0.62
