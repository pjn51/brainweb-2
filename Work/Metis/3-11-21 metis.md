# Metis Notes for Thursday, March 11th
`LINKS:` [[metis week 10]]
`TAGS:` #meeting/career

---
Today we have an assessment on EDA and then we have a session on data ethics.

## Lecture - [[data ethics]]
When we talk about ethical [[data science]], we're talking a lot about privacy, confidentiality, consent, and bias. 

There are various concerns we might have when we're starting a project. Is it ethical in a personal sense? Would you be ok with your actions being publicized? Additionally, is it ethical in an organizational sense? Are you breaking company rules? Also, is it legal?

There is no rulebook for ethical [[data science]]. There are *guidelines*, but there are no binding rules. We have to come up with these rules ourselves. 

An interesting book to check out is *Weapons of Math Destruction.* It's about how these tools can be used as weapons, either for a good cause or for a bad one. 

### Why Study Data Ethics?
Data science has a history of harm. People only started to care about this stuff very recently. Data science has been around a *long time.* 

### Before We Start...
Before we start a project, we should examine ethical concerns. Most ethical problems can be avoided if we look ahead. The real value of data scientists is that we can know what questions to ask before we start a project. 

We should have a *value proposition* for each project. This is a statement of intention for the project. Why are we doing the project, and what will we use this tool for after we create it? 

This value proposition has ethical content. We can tell if it's an ethical goal, and if there are any red flags in the proposition. We should ask ourselves what would happen if the model worked really badly, or really well. Would the world be better or worse in either of those cases?

We also have to think about if the project is plausible. Impossible tasks tend to lead to inaccurate models, and innacurate models tend to lead to harmful results. 

Does the model offload ethical decisions? Data analytics provides *interpretation* and *prediction*. In the case of interpretation, we have to think about who will be interpreting, and if they have the expertise to understand those interpretations correctly, especially in the case of error being present. In the case of prediction, the ethical risk comes when these predictions allow people to pursue harmful goals. 

### Bias
Bias can appear in many ways. 

Bias during [[data]] generation occurs when there's a historical bias, and we sample from these historical datasets. Of course, this will lead to a representation bias in our data, and therefore our models will replicate this in terms of measurement bias and a biased result. 

We can also have bias during the evaluation process. Depending on the benchmarks that we use to grade our success, we can have all sorts of biases that appear. Aggregation bias occurs when we [[ensembling|enseble]] multiple models. 

Often the most ignored form of bias is deployment bias. Even if the tool is unbiased, how are people really using the tool? Are they deploying it in a way that is fair?

The most abstract of all is design bias. By picking a topic to classify or predict implies a bias right off the bat. We have to choose what we think is important in the world. There are an infinite number of features for any classification problem. Therefore, based on the features we choose to use, we can make any number of groups appear. 

> There are no bias-free learning algorithms
> \- Watanabee

When models are reused or built on top of other models, they inherit all the biases of the past model. This also applies to the dataset that we build models on top of. We inherit all the biases of the information we use.  

### Weapons of Math Destruction
There are a few key characteristics that identify something as a "weapon of math destruction."

==Opaque==: These models are hard to understand, and therefore hard to detect bias and inaccuracy within. 

==Lack of checks==: Without internal and internal review, models can be used for harm more easily. Review boards with both expert and non-expert members can mitigate this.

==Large scale==: Models that have wide-ranging effects have more potential for harm, and small biases are more important. 

Proxies are a dangerous game. When we try and measure something using something that we believe is related to it, we import our own biases. When we can't measure something directly, we should think about changing the way that we're approaching the problem. 

### Consent
This is mostly important when it comes to gathering data. We need to have *meaningful approval* by those that we affect. This is important when gathering data on users. 

We have to consider the burden of consent. Whose job is it to make sure consent is given, the consumer, or the developer?

There are lots of questions we should ask. 
- Will the user be negatively affected? 
- Does the user know what they're getting into? 
- Can the user withdraw consent?

### Conclusion
We should aim to create tools that empower people and give people more agency. We should look to Wikipedia compared to Facebook. 

## Case Studies in Data Ethics
### Predicting Recidivism
A company called Northpointe built a tool to predict whether a convicted defendant would commit a crime again. This tool would be used to determine sentencing and parole. 

The algorithm was more strict towards Black people, and had much more false positives when it came to that population. Additionally, it only had an [[accuracy]] score of around 60%. This model has been used by multiple states when determining pretrial release decisions. 

### Loan Decisions
What if we worked at a bank, and were told to build an algorithm that would determine if the applicant for a loan should be approved. if we don't have a ground truth for who should get a loan, how can we engineer a proxy for this?

If we go off of who has been denied a loan in the past, we will replicate the history of discriminative lending. 

### Predictive Policing
What if a police department asked us to create a model that would allow them to distribute their police patrols more efficiently? If we use locations of past arrests, we will certainly begin to target police to minority and low-income areas where police already spend most of their time. 

## [[career]] workshop - alumni panel
We have three alumni who will share their transition experience with us. 

### Nick (Fall 2020)
#### Background
He has a background in music, and didn't know anything about python or data science at all a year ago. He just got a job as a data analyst for a language consultant company.

He interviewed with his current company in September 2020, but he wasn't qualified at all. After the bootcamp, he connected with them again. They work on the language that companies use internally and for PR purposes. They specialize in helping companies handle a crisis through the use of language. 

The interview process involved an initial interview, and a take-home test. They gave him survey responses about peoples' impressions on what good and bad foods are. He did topic modeling and [[sentiment analysis]] on that stuff, which felt basic but it impressed them. It helped him nail the process.

At his (very) new role, he does a ton of [[NLP]]. The role is very new for the company as well, so he's still figuring it out. 

#### Advice
Be yourself. After you graduate, you're still you. Rely on the strengths that you had before Metis as well as the skills you learned. 

Don't let yourself get frustrated by lack of response. You aren't entitled to anything. 

### Molly (Winter 2020)
#### Background
She studied biophysics in college, but wanted to explore other options after she graduated. She got into the digital marketing space, and was drawn to the analytics side. 

She took some online coding classes, and found Metis. After taking a pre-course, she dove into the bootcamp. She graduated in March 2020, and it was pretty challenging to find a job. Most companies put a freeze on hiring at that time. 

After she graduated, she knew she wanted to be at a bigger company, and ended up getting a job at the Mars candy company. 

At her job, she works with the global business team to create financial forecasting models. She does a ton of time-series stuff, and works with tools like [[PySpark]] and Azure, as well as a tiny bit of [[R]]. 

#### Advice
Because of Metis, we have a lot of skills compared to other people with our experience level. But lots of people still have these skills. We need to create *stories* about ourselves and the really unique things that we bring to the table. 

We have the hard skills - pump up your soft skills alongside those, because that's what helps you stand out from other applicants who have the same keywords on their resume. 

Cover letters are super important. Put effort into them because that's where you sell your soft skills and create the story about who you are. 

As for [[R]] vs [[Python]], the language you know is secondary to your ability to learn. If you know the fundamentals, and know how to teach yourself skills, that's all that matters.

### Ahmed (NYC Summer 2016)
#### Background
He did stats and psychology in college, and thought he wanted to go the academic route. He changed his mind, and after he went to a Metis open-house he decided to do the bootcamp. 

After he graduated in September 2016, he got a job through the alumni slack as a data analyst for GrubHub. He did that for a year, and then he got two offers - one was a pure data science role, and the other was more of a data engineer thing. 

He took the data engineer one to round out his resume a little bit, and it turned out that he loves data engineering. He stayed at that position for three years, and just transitioned to a new role for data engineering at a company called Fullcode.

Fullcode works with QR codes to try and gather data about offline ads and how many people view them. They also apply [[NLP]] to [[HTML]] to classify websites. He kind of exists between the engineering team and the ML team. 

#### Advice
After we get the first data sci job, we won't have to look for jobs anymore. Jobs will be looking for us. The hardest step is getting the first job. 

Data science is a great field. Even through [[COVID-19]], opportunities have remained stable or even improved. 

He wants us to reach out to him if we have issues with the job search. Somebody reached out to him on LinkedIn about a position at his company asking for an info interview. He agreed, and the referral he later gave her let her skip the line.

Referrals are gold. So many people apply to every position that its like winning the lottery to get a job through a cold application. 

