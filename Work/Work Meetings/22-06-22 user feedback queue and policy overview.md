# User feedback queue and policy overview
on [[22-06-22 Wed]]
with [[Kevin]], [[Brian]], [[Megan]]

---
In this meeting led my Megan, we skimmed a few [[PM queues]] and ways that job seekers are able to provide feedback. 

# How does feedback arrive?
There are a few ways that feedback can get into our queues for categorization and labeling. When seekers report a job or indicate "Not Interested," they are able to leave text feedback. If they leave a comment, it will be put into a [[Labeler]] queue. 

# Report a job (RAJ)
Megan complained a bit about [[Report A Job|RAJ]], saying that there are *a ton* of buckets that comments are sorted into. To be specific, there are over 60. The most important buckets are the fraud, spam, and discrimination ones. Inside the spam bucket, there's an adult industry bucket that contains reports of sex work, an industry not permitted on [[Indeed]]. The fraud bucket contains reports of human trafficing, which are reviewed daily by an in-house analyst. 

The purpose of RAJ is a mixed bag. On one hand, it's concerned with [[data annotation]] and gathering [[data]] for analysis by people like me. On the other hand, it's also used as a source of actionable information. Teams in Japan and Germany take the actionable comments and investigate them. 

There's another team called JLM, which stands for Job Level Moderation. They're more interested in the actionable side, and operate under the Data Operations team. 

# Net promoter score (NPS)
The NPS is a metric that is calculated from jobseeker feedback. Questions are sent to some users, asking them how likely they are to recommend Indeed to a friend. This also allows the user to leave text feedback. This queue has relatively low volume, so it's possible to manually review all comments. These surveys are sent to jobseekers and employers, but our team only really works with the jobseeker side. 

If the jobseeker reports a 9 or above on the scale, they are classified as a promoter. If their score is lower than 7, we call them "detractors." These scores are not objective in any way, because sometimes people report a low score, but explain that it isn't really Indeed's fault, and sometimes a high score contains a scathing explanation. 

There aren't nearly as many buckets for these comments to be sorted into. Note that this is only rolled out to the english-speaking markets. 

# Relrating queues for Invite 2 Apply
When jobseekers are notified with a suggestion to apply to a specific job, they can leave feedback here. They rate the relevancy of the job from one to five, and can leave a comment. These are sorted into buckets, and run into a little quirk. Sometimes jobseekers specify what they would *rather* have suggested to them, and sometimes they just complain that the job is bad. 

# The SERP relevance queue
At the bottom of the search page, jobseekers can leave a comment about the quality of their search results. We can't see the jobs that they saw before leaving feedback, only the query and the page that they left feedback on. They report a relevancy score as well as a comment. This score and comment could relate to the quality of reccomendation on their home page, the quality of a search result, or the quality of an individual job, again - which we cannot see. This all gets fed into the [[SERP Relevance queue]]. 

# Mid-apply feedback queue
This is a relatively new queue, launched in Q2 2022. When you use Indeed Apply, you can leave feedback at multiple stages of the process. The most common bucket that these comments get put into is the "Resume and cover letter" one. We can see the job title, the page that they left feedback, and the feedback itself. We put this into the [[MidApply Feedback queue]]. 

# Applications for feedback
With feedback, particularly the mid-apply feedback, we can improve the user experience of tools since people often complain about pain points of the process. 

UX is responsible for the way that feedback is left, and there have been issues between our team and them before. We would like to structure the text entry more, so that we can get a clearer idea of what people are trying to say, since comments are often very vague. However, when we've tried to do this, we see the number of reports related to fraud drop, which is a huge red flag that we're discouraging people from reporting abuse of the platform. 

# ðŸ’¥ Action items


---
