*ML tools can be black boxes.* For our modern [[machine learning]] algorithms, and especially the [[deep learning]] tools of today, it is very difficult to understand why the algorithm is coming to the conclusion that it presents. We can grade the accuracy, precision, recall, and other metrics, but it is nearly impossibly to conceptualize the actual decision-making process that the model is using. 

This presents challenges when we're allowing such models to make really important decisions.

#idea/compsci/data-science 

---
```dataview
LIST
FROM [[ML tools can be black boxes]] AND -outgoing([[ML tools can be black boxes]])
```